{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedbd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wandb\n",
    "import os\n",
    "from ipywidgets import widgets, VBox, HBox, Button, Textarea, Label, BoundedIntText, ToggleButton\n",
    "from IPython.display import display, clear_output, Javascript\n",
    "from datetime import datetime\n",
    "from IPython import get_ipython\n",
    "\n",
    "from ipywidgets import Layout\n",
    "\n",
    "# gpt-5\n",
    "# gpt-4o-realtime-preview\n",
    "# gpt-4o-mini-realtime-preview\n",
    "# gpt-5-chat-latest\n",
    "used_model=\"gpt-5-chat-latest\"\n",
    "\n",
    "llm_output_box = Textarea(\n",
    "    description='LLM output:',\n",
    "    layout=Layout(width='80%', height='220px', flex='1 1 auto'),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# ===== 文件路径 =====\n",
    "# LLM4Molecule_curated/SFT_Qwen2.5-7B/epoch_6_lr5e-5_2/test_preds\n",
    "path=\"./\"\n",
    "input_file = path + \"RL_need_curate_data.jsonl\"\n",
    "curated_file = path + \"RL_curated.jsonl\"\n",
    "log_file = path + \"RL_record.log\"\n",
    "config_file = path + \"RL_config.json\"\n",
    "LLM_LOG_FILE = path + \"RL_record_LLM.log\"   # 新增：LLM 日志\n",
    "\n",
    "# ===== 加载 config 状态 =====\n",
    "if os.path.exists(config_file):\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    current_index = config.get(\"current_index\", 0)\n",
    "    wandb_run_id = config.get(\"wandb_run_id\", wandb.util.generate_id())\n",
    "else:\n",
    "    current_index = 0\n",
    "    wandb_run_id = wandb.util.generate_id()\n",
    "\n",
    "# ===== 初始化 wandb =====\n",
    "wandb.init(\n",
    "    project=\"molecule-curation\",\n",
    "    name=\"curation-session\",\n",
    "    entity=\"byfrfy\",\n",
    "    id=wandb_run_id,\n",
    "    resume=\"allow\"\n",
    ")\n",
    "        \n",
    "\n",
    "def save_config():\n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            \"current_index\": current_index,\n",
    "            \"wandb_run_id\": wandb_run_id\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ===== 加载数据 =====\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "if not os.path.exists(curated_file):\n",
    "    with open(curated_file, 'w', encoding='utf-8') as f:\n",
    "        for record in data:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "curated_data=[]\n",
    "\n",
    "curated_data = []\n",
    "\n",
    "with open(curated_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line is not None and line.strip():   # 确保非空行\n",
    "            try:\n",
    "                curated_data.append(json.loads(line.strip()))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error: {e} | Line content: {line}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e} | Line content: {line}\")\n",
    "\n",
    "print(f\"Loaded {len(curated_data)} records from {curated_file}\")\n",
    "\n",
    "answer_list=[]\n",
    "test_path=\"./test_data.txt\"\n",
    "with open(test_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        answer, description = line.strip().split(\"\\t\")\n",
    "        answer_list.append(answer)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i]['answer'] = answer_list[i]\n",
    "\n",
    "modified_indices = set()\n",
    "print(f\"✅ 已加载 {len(data)} 条记录\")\n",
    "\n",
    "# ===== 日志函数 =====\n",
    "def log_action(action_type, index, record=None):\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    log_entry = {\"timestamp\": timestamp, \"action\": action_type, \"index\": index}\n",
    "    if record:\n",
    "        log_entry[\"record\"] = record\n",
    "\n",
    "    with open(log_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(log_entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    wandb.log({\n",
    "        \"timestamp\": timestamp,\n",
    "        \"action\": action_type,\n",
    "        \"index\": index,\n",
    "        \"text_length\": len(json.dumps(record, ensure_ascii=False)) if record else 0\n",
    "    })\n",
    "\n",
    "common_layout = widgets.Layout(width='150px', height='40px')\n",
    "# ===== 文本框控件 =====\n",
    "# 左侧打分框（仅保存到 merged_data_all.jsonl）\n",
    "edit_score_box = BoundedIntText(value=3, min=1, max=5, description='score:')\n",
    "\n",
    "# 左侧（编辑原始数据）\n",
    "edit_smile_box = Textarea(description='smile:', layout=widgets.Layout(width='90%', height='30px'), disabled=True)\n",
    "edit_explain_box = Textarea(description='explain:', layout=widgets.Layout(width='90%', height='50px'), disabled=True)\n",
    "edit_cot_box = Textarea(description='cot:', layout=widgets.Layout(width='90%', height='260px'))\n",
    "# 左侧 reason 文本框（保存到 curated 文件）\n",
    "edit_reason_box = Textarea(description='reason:', layout=widgets.Layout(width='90%', height='50px'))\n",
    "\n",
    "# 右侧打分框（随修改保存到 curated 文件）\n",
    "curated_score_box = BoundedIntText(value=5, min=1, max=5, description='score\\n[curated]:',style={'description_width': '160px'})\n",
    "\n",
    "# 右侧（只读显示保存内容）\n",
    "curated_smile_box = Textarea(description='smile\\n[curated]:', layout=widgets.Layout(width='90%', height='30px'), disabled=True, style={'description_width': '160px'})\n",
    "curated_explain_box = Textarea(description='explain\\n[curated]:', layout=widgets.Layout(width='90%', height='50px'), disabled=True, style={'description_width': '160px'})\n",
    "curated_cot_box = Textarea(description='cot\\n[curated]:', layout=widgets.Layout(width='90%', height='260px'), disabled=True, style={'description_width': '160px'})\n",
    "curated_reason_box = Textarea(description='reason\\n[curated]:', layout=widgets.Layout(width='90%', height='50px'), disabled=True, style={'description_width': '160px'})\n",
    "\n",
    "# ===== 新增：LLM assistant 开关与输出框 =====\n",
    "\n",
    "llm_toggle = ToggleButton(\n",
    "    value=True,                      # ← 默认开启\n",
    "    description='LLM assistant',\n",
    "    button_style='success'           # ← 绿色\n",
    ")\n",
    "llm_toggle.tooltip = \"选中后在切换记录时调用 LLM 生成参考\"\n",
    "\n",
    "# llm_toggle = ToggleButton(value=False, description='LLM assistant', button_style='')\n",
    "# llm_toggle.tooltip = \"选中后在切换记录时调用 LLM 生成参考\"\n",
    "# llm_output_box = Textarea(description='LLM output:', layout=widgets.Layout(width='100%', height='260px'), disabled=True)\n",
    "\n",
    "# 控制按钮\n",
    "# 全屏按钮\n",
    "fullscreen_button = Button(description=\"全屏\", button_style='')\n",
    "fullscreen_button.tooltip = \"切换全屏 (Ctrl+Shift+F)\"\n",
    "\n",
    "def toggle_fullscreen(_=None):\n",
    "    # 用 data-widget-id 精确定位到 ui 的 DOM 元素，并切换全屏\n",
    "    display(Javascript(f\"\"\"\n",
    "        (function() {{\n",
    "            const el = document.querySelector('[data-widget-id=\"{ui._model_id}\"]');\n",
    "            if (!el) {{ console.warn('ui root not found'); return; }}\n",
    "            const target = el.closest('.jupyter-widgets-view') || el;\n",
    "            if (document.fullscreenElement) {{\n",
    "                document.exitFullscreen();\n",
    "            }} else {{\n",
    "                if (target.requestFullscreen) {{\n",
    "                    target.requestFullscreen().catch(err => console.error(err));\n",
    "                }} else if (target.webkitRequestFullscreen) {{\n",
    "                    target.webkitRequestFullscreen();\n",
    "                }}\n",
    "            }}\n",
    "        }})();\n",
    "    \"\"\"))\n",
    "\n",
    "fullscreen_button.on_click(toggle_fullscreen)\n",
    "\n",
    "\n",
    "\n",
    "index_label = Label()\n",
    "prev_button = Button(description=\"Previous\", button_style='info')\n",
    "next_button = Button(description=\"Next\", button_style='info')\n",
    "save_button = Button(description=\"Save Changes\", button_style='success')\n",
    "export_button = Button(description=\"Export Records\", button_style='warning')\n",
    "jump_input = BoundedIntText(value=current_index+1, min=1, max=len(data), description='Jump to:')\n",
    "jump_button = Button(description=\"Jump\", button_style='primary')\n",
    "show_modified_button = Button(description=\"📋 View Modified\", button_style='warning')\n",
    "export_modified_button = Button(description=\"📝 Export Modified\", button_style='success')\n",
    "\n",
    "# ====== LLM 相关：沿用你原来的 client + 模板 ======\n",
    "# 你的静态示例 COT 与模板（保持不动）\n",
    "\n",
    "prompt_template_head = f\"\"\"\n",
    "Analyze whether the reasoning is correct. The reasoning is generated based on the given description, where the target molecule has already been specified. If the molecule derived from the reasoning matches the target molecule, it is correct. If it does not match, errors in the reasoning should be corrected so that the reasoning can generate the target molecule.\n",
    "\n",
    "Key point 1: The goal is to generate the target molecule. If it is incorrect, the CoT should be carefully revised so that it can generate the target molecule from the description. Make revisions based on the original text and **provide a complete, copyable CoT in Markdown format directly**. Modify only the incorrect or problematic parts; do not change information that is already correct, and keep the original formatting as much as possible.\n",
    "\n",
    "Key point 2: Then check whether the CoT before and after revision has any issues, especially in the structure and functional group descriptions, and correct them if necessary.\n",
    "\n",
    "Key point 3: If possible, base your revisions on the original text, modifying only the incorrect or problematic parts without altering information that is already correct. You do not need to mark the changes directly in the revised CoT; instead, list them before the completed CoT.\n",
    "\n",
    "Key point 4: every original CoT has a summarisation before giving the SMILES, you should keep every original summarisation based on the **original CoT**. For example some CoT contains: (1) Putting this together, we arrive at the correct SMILES representation for chlorobenzene:\\n<answer>SMILES</answer> (2) Assembling all parts, the complete SMILES representation for benzoin is:\\n<answer>SMILES</answer> (3) Now that we have a clear understanding of the structure, we can convert this into its SMILES notation:\\n<answer>SMILES</answer> (4) The SMILES for 2-isopropylmalic acid is as follows:\\n<answer>SMILES</answer> **You should follow the the original CoT**.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ===== OpenAI Client（沿用你给的写法；如用环境变量可自行替换） =====\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"sk-xxx\")  # your API Key\n",
    "\n",
    "# ===== 动态构造 prompt（使用当前记录的 explain/cot/目标 smile） =====\n",
    "def build_prompt_with_current_record():\n",
    "    \"\"\"\n",
    "    使用左侧编辑框内容构造 Prompt：\n",
    "    - 描述  ← edit_explain_box.value\n",
    "    - 推理  ← edit_cot_box.value\n",
    "    - 目标  ← edit_smile_box.value\n",
    "    \"\"\"\n",
    "    current_explain = (edit_explain_box.value or \"\").strip()\n",
    "    current_cot = (edit_cot_box.value or \"\").strip()\n",
    "    current_target_smile = (edit_smile_box.value or \"\").strip()\n",
    "\n",
    "    dynamic_cot = (\n",
    "        \"Now, please start analysis:\\n\\n\"\n",
    "        \"描述：\\n\"\n",
    "        f\"{current_explain}\\n\\n\"\n",
    "        \"推理：\\n\"\n",
    "        f\"{current_cot}\\n\\n\"\n",
    "        \"目标：\\n\"\n",
    "        f\"{current_target_smile}\\n\"\n",
    "    )\n",
    "\n",
    "    return f\"{prompt_template_head}\\n\\n{dynamic_cot}\"\n",
    "\n",
    "# def call_llm_and_display():\n",
    "#     \"\"\"当开关选中时：在切换记录后调用 LLM，将输出显示到 llm_output_box（不写日志）。\"\"\"\n",
    "#     if not llm_toggle.value:\n",
    "#         return\n",
    "#     try:\n",
    "#         # 使用“当前记录”的动态 prompt，以满足“对应调用”的需求\n",
    "#         prompt_current = build_prompt_with_current_record()\n",
    "#         # print(prompt_current)\n",
    "#         resp = client.responses.create(\n",
    "#             model=\"gpt-5\",\n",
    "#             instructions=\"You are an expert of chemistry.\",\n",
    "#             input=prompt_current\n",
    "#         )\n",
    "#         out_text = resp.output_text if hasattr(resp, \"output_text\") else str(resp)\n",
    "#         llm_output_box.value = out_text  # 只显示\n",
    "#     except Exception as e:\n",
    "#         llm_output_box.value = f\"LLM 调用失败：{e}\"\n",
    "def call_llm_and_display():\n",
    "    \"\"\"当开关选中时：在切换记录后调用 LLM，将输出显示到 llm_output_box，并把本次查询写入 record_LLM.log。\"\"\"\n",
    "    if not llm_toggle.value:\n",
    "        return\n",
    "\n",
    "    # 先构造 prompt，便于失败时也能记录\n",
    "    prompt_current = build_prompt_with_current_record()\n",
    "\n",
    "    try:\n",
    "        resp = client.responses.create(\n",
    "            model=used_model,  # 保持你现有配置\n",
    "            instructions=\"You are an expert of chemistry.\",\n",
    "            input=prompt_current\n",
    "        )\n",
    "        out_text = resp.output_text if hasattr(resp, \"output_text\") else str(resp)\n",
    "\n",
    "        # 显示到界面\n",
    "        llm_output_box.value = out_text\n",
    "\n",
    "        # —— 记录“每条查询”到文件（逐行 JSON）——\n",
    "        llm_log = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"index\": current_index,\n",
    "            \"event\": \"llm_query\",\n",
    "            \"model\": used_model,\n",
    "            \"prompt_len\": len(prompt_current),\n",
    "            \"output_len\": len(out_text),\n",
    "            \"prompt\": prompt_current,\n",
    "            \"output\": out_text\n",
    "        }\n",
    "        with open(LLM_LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(llm_log, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        # 显示错误\n",
    "        llm_output_box.value = f\"LLM 调用失败：{e}\"\n",
    "\n",
    "        # —— 失败也记录到日志 —— \n",
    "        err_log = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"index\": current_index,\n",
    "            \"event\": \"llm_query_error\",\n",
    "            \"model\": used_model,\n",
    "            \"error\": str(e),\n",
    "            \"prompt_len\": len(prompt_current),\n",
    "            \"prompt\": prompt_current\n",
    "        }\n",
    "        with open(LLM_LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(err_log, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# ===== 记录切换/保存时的 UI 逻辑 =====\n",
    "\n",
    "def load_record(index):\n",
    "    \"\"\"加载 index 记录并在需要时调用 LLM。\"\"\"\n",
    "    global current_index\n",
    "    current_index = index\n",
    "    save_config()\n",
    "\n",
    "    # 左侧\n",
    "    record = data[index]\n",
    "    edit_smile_box.value = record.get(\"answer\", \"\")\n",
    "    edit_explain_box.value = record.get(\"explain\", \"\")\n",
    "    edit_cot_box.value = record.get(\"cot\", \"\")\n",
    "    edit_score_box.value = record.get(\"curation_score\", 3)\n",
    "    edit_reason_box.value = curated_data[index].get(\"reason\", \"\")\n",
    "\n",
    "    # 右侧\n",
    "    saved = curated_data[index]\n",
    "    curated_smile_box.value = saved.get(\"smile\", \"\")\n",
    "    curated_explain_box.value = saved.get(\"explain\", \"\")\n",
    "    curated_cot_box.value = saved.get(\"cot\", \"\")\n",
    "    curated_score_box.value = saved.get(\"curation_score\", 5)\n",
    "    curated_reason_box.value = curated_data[index].get(\"reason\", \"\")\n",
    "\n",
    "    index_label.value = f\"Current Record: {index + 1} / {len(data)}\"\n",
    "    jump_input.value = index + 1\n",
    "\n",
    "    # 若开关开启，则每次切换记录时调用 LLM 并显示\n",
    "    if llm_toggle.value:\n",
    "        call_llm_and_display()\n",
    "    else:\n",
    "        llm_output_box.value = \"\"\n",
    "\n",
    "def save_current(_=None):\n",
    "    updated_right = {\n",
    "        'smile': edit_smile_box.value,\n",
    "        'explain': edit_explain_box.value,\n",
    "        'cot': edit_cot_box.value,\n",
    "        'curation_score': curated_score_box.value,\n",
    "        'reason': edit_reason_box.value\n",
    "    }\n",
    "    updated_left_score = edit_score_box.value\n",
    "\n",
    "    # 更新右侧（curated 文件）\n",
    "    if curated_data[current_index].get('smile') != updated_right['smile'] or \\\n",
    "       curated_data[current_index].get('explain') != updated_right['explain'] or \\\n",
    "       curated_data[current_index].get('cot') != updated_right['cot'] or \\\n",
    "       curated_data[current_index].get('curation_score') != updated_right['curation_score']:\n",
    "        curated_data[current_index].update(updated_right)\n",
    "        modified_indices.add(current_index)\n",
    "\n",
    "        # 写入 updated_right 到 curated_file\n",
    "        with open(curated_file, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        lines[current_index] = json.dumps(curated_data[current_index], ensure_ascii=False) + '\\n'\n",
    "        with open(curated_file, 'w', encoding='utf-8') as f:\n",
    "            f.writelines(lines)\n",
    "\n",
    "    # 更新左侧分数到原始文件\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        input_lines = f.readlines()\n",
    "    original_record = json.loads(input_lines[current_index])\n",
    "    original_record['curation_score'] = updated_left_score\n",
    "    input_lines[current_index] = json.dumps(original_record, ensure_ascii=False) + '\\n'\n",
    "    with open(input_file, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(input_lines)\n",
    "\n",
    "    log_action(\"save\", current_index, {\n",
    "        \"left_score\": updated_left_score,\n",
    "        \"right_data\": updated_right\n",
    "    })\n",
    "\n",
    "    # 若开关开启：保存时把当前显示在 llm_output_box 里的内容写入 record_LLM.log（不重新调用 LLM）\n",
    "    if llm_toggle.value:\n",
    "        try:\n",
    "            out_text = llm_output_box.value or \"\"\n",
    "            llm_log = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"index\": current_index,\n",
    "                \"output_len\": len(out_text),\n",
    "                \"output\": out_text\n",
    "            }\n",
    "            with open(LLM_LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "                f.write(json.dumps(llm_log, ensure_ascii=False) + '\\n')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f\"✅ 已保存第 {current_index + 1} 条记录（左分数+右内容）\")\n",
    "    display(ui)\n",
    "\n",
    "def prev_record(_=None):\n",
    "    if current_index > 0:\n",
    "        log_action(\"prev\", current_index)\n",
    "        load_record(current_index - 1)\n",
    "\n",
    "def next_record(_=None):\n",
    "    if current_index < len(data) - 1:\n",
    "        log_action(\"next\", current_index)\n",
    "        load_record(current_index + 1)\n",
    "\n",
    "def jump_to_index(_=None):\n",
    "    idx = jump_input.value - 1\n",
    "    if 0 <= idx < len(data):\n",
    "        log_action(\"jump\", current_index)\n",
    "        load_record(idx)\n",
    "\n",
    "def export_modified_records(_):\n",
    "    if not modified_indices:\n",
    "        print(\"ℹ️ 没有修改记录可导出\")\n",
    "        return\n",
    "    export_file = \"modified_records.jsonl\"\n",
    "    with open(export_file, 'w', encoding='utf-8') as f:\n",
    "        for idx in sorted(modified_indices):\n",
    "            f.write(json.dumps(curated_data[idx], ensure_ascii=False) + '\\n')\n",
    "    print(f\"✅ 已导出 {len(modified_indices)} 条修改记录到 {export_file}\")\n",
    "\n",
    "def show_modified_records(_):\n",
    "    clear_output(wait=True)\n",
    "    if not modified_indices:\n",
    "        print(\"ℹ️ 暂无已修改记录\")\n",
    "    else:\n",
    "        indices = sorted(modified_indices)\n",
    "        print(f\"📋 已修改 {len(indices)} 条记录：{[i+1 for i in indices]}\")\n",
    "    display(ui)\n",
    "\n",
    "# 绑定快捷键（仅支持 Jupyter Notebook 前端）\n",
    "# def bind_shortcuts():\n",
    "#     display(Javascript(\"\"\"\n",
    "#         document.addEventListener('keydown', function(event) {\n",
    "#             if (event.ctrlKey && event.key === 'ArrowRight') {\n",
    "#                 document.querySelector('button[title=\"下一条\"]').click();\n",
    "#             }\n",
    "#             if (event.ctrlKey && event.key === 'ArrowLeft') {\n",
    "#                 document.querySelector('button[title=\"上一条\"]').click();\n",
    "#             }\n",
    "#             if (event.ctrlKey && event.key === 's') {\n",
    "#                 event.preventDefault();\n",
    "#                 document.querySelector('button[title=\"保存当前修改\"]').click();\n",
    "#             }\n",
    "#         });\n",
    "#     \"\"\"))\n",
    "def bind_shortcuts():\n",
    "    display(Javascript(\"\"\"\n",
    "        document.addEventListener('keydown', function(event) {\n",
    "            if (event.ctrlKey && event.key === 'ArrowRight') {\n",
    "                document.querySelector('button[title=\"下一条\"]').click();\n",
    "            }\n",
    "            if (event.ctrlKey && event.key === 'ArrowLeft') {\n",
    "                document.querySelector('button[title=\"上一条\"]').click();\n",
    "            }\n",
    "            if (event.ctrlKey && event.key === 's') {\n",
    "                event.preventDefault();\n",
    "                document.querySelector('button[title=\"保存当前修改\"]').click();\n",
    "            }\n",
    "            // 新增：Ctrl+Shift+F 切换全屏\n",
    "            if (event.ctrlKey && event.shiftKey && event.key.toLowerCase() === 'f') {\n",
    "                const btn = Array.from(document.querySelectorAll('button'))\n",
    "                  .find(b => b.getAttribute('title') === '切换全屏 (Ctrl+Shift+F)');\n",
    "                if (btn) btn.click();\n",
    "            }\n",
    "        });\n",
    "    \"\"\"))\n",
    "\n",
    "# 为按钮设置 title，方便 JavaScript 查找并触发\n",
    "prev_button.tooltip = \"上一条\"\n",
    "next_button.tooltip = \"下一条\"\n",
    "save_button.tooltip = \"保存当前修改\"\n",
    "\n",
    "# 绑定事件\n",
    "save_button.on_click(save_current)\n",
    "prev_button.on_click(prev_record)\n",
    "next_button.on_click(next_record)\n",
    "jump_button.on_click(jump_to_index)\n",
    "export_modified_button.on_click(export_modified_records)\n",
    "show_modified_button.on_click(show_modified_records)\n",
    "\n",
    "# LLM 开关切换时的即时行为：打开即对当前记录生成；关闭则清空显示\n",
    "def _on_llm_toggle_change(change):\n",
    "    if change['name'] == 'value':\n",
    "        if change['new']:\n",
    "            call_llm_and_display()\n",
    "        else:\n",
    "            llm_output_box.value = \"\"\n",
    "\n",
    "llm_toggle.observe(_on_llm_toggle_change)\n",
    "\n",
    "# UI 布局（左右分栏）\n",
    "left_boxes = VBox([\n",
    "    edit_smile_box, \n",
    "    edit_explain_box, \n",
    "    edit_cot_box, \n",
    "    edit_score_box, \n",
    "    edit_reason_box\n",
    "], layout=widgets.Layout(width='50%'))\n",
    "\n",
    "right_boxes = VBox([\n",
    "    curated_smile_box,\n",
    "    curated_explain_box,\n",
    "    curated_cot_box,\n",
    "    curated_score_box,\n",
    "    curated_reason_box,\n",
    "    # llm_output_box,   # 新增：展示 LLM 输出\n",
    "], layout=widgets.Layout(width='50%'))\n",
    "\n",
    "ui = VBox([\n",
    "    index_label,\n",
    "    HBox([left_boxes, right_boxes]),\n",
    "    HBox([prev_button, next_button, llm_toggle, save_button, export_button]),  # 新增：llm_toggle\n",
    "    HBox([jump_input, jump_button]),\n",
    "    HBox([show_modified_button, export_modified_button])\n",
    "])\n",
    "top_llm_row = HBox([llm_output_box], layout=widgets.Layout(width='100%'))\n",
    "\n",
    "ui = VBox([\n",
    "    top_llm_row,  # ← 顶部横栏：LLM 输出放这里\n",
    "    index_label,\n",
    "    HBox([left_boxes, right_boxes]),\n",
    "    # HBox([prev_button, next_button, llm_toggle, fullscreen_button, save_button, export_button]),## 不使用全屏\n",
    "    HBox([prev_button, next_button, save_button, export_button]),\n",
    "    HBox([jump_input, jump_button]),\n",
    "    HBox([show_modified_button, export_modified_button, llm_toggle])\n",
    "])\n",
    "\n",
    "# 初始显示\n",
    "load_record(current_index)\n",
    "bind_shortcuts()\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801ae33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
